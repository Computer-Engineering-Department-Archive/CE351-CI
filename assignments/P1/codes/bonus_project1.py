# -*- coding: utf-8 -*-
"""Bonus_Project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bucurhsHXHm5PINP8lWR-mBnl257qlAy

# Import Libraries
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import datasets, models, transforms
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tqdm.auto import tqdm
import os

!export CUDA_LAUNCH_BLOCKING=1
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

"""## For Google Colab Users

This cell is for mounting your Google Drive to the Colab Notebook. If you are not using Google Colab, you can skip this cell
"""

from google.colab import drive
drive.mount('/content/drive')

# Check for GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# Check for GPU in mac
# device = "mps" if torch.backends.mps.is_available() else "cpu"

device

"""# Data

## Transforming Data
"""

data_transforms = {

    'Training' : transforms.Compose([
        transforms.RandomResizedCrop((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()
    ]),
    'Testing': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()

    ])
}

"""## Loading Data"""

# directory: where training and testing data are
base_path = os.getcwd()
data_dir = os.path.join(base_path, '/content/drive/MyDrive/Colab Datasets/MRI/')

### START CODE HERE

# datasets.ImageFolder: (https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)
# torch.utils.data.DataLoader: (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)


# image_datasets are dictionary of (type of dataset, dataloader)
# type of dataset are training and testing
dataset_types = ['Training', 'Testing']
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in dataset_types}

# DataLoader helps us for better performance and experience in data loading
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in dataset_types}
### END CODE HERE

dataset_sizes = {x: len(image_datasets[x]) for x in dataset_types}
class_names = image_datasets['Training'].classes

dataset_sizes, class_names

"""## Samples of data"""

samples, labels = next(iter(dataloaders['Testing']))
plt.figure(figsize=(17, 10))
plt.axis('off')
for i in range(32):
    plt.subplot(4, 8, i+1)
    plt.imshow(samples[i].permute(1, 2, 0))
    plt.title(class_names[labels[i]])
    plt.axis('off')

"""# Model

## Loading Model
"""

# Loading are pretrained model in this task our model is resnet50 (https://www.youtube.com/watch?v=mGMpHyiN5lk)
### START CODE HERE
from torchvision.models import resnet50, ResNet50_Weights
# Loading pretrained model
model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
for param in model.parameters():
    param.requires_grad = False
### END CODE HERE
model

"""## Preparing Model"""

### START CODE HERE
out_features = 4
hidden_layer_neurons = 256

# You have to change the (fc) layer of the model to compatible with your data
# model.fc = nn.Linear(model.fc.in_features, out_features)
model.fc = nn.Sequential(nn.Linear(model.fc.in_features, hidden_layer_neurons),
                          nn.ReLU(),
                          nn.Linear(hidden_layer_neurons, hidden_layer_neurons),
                          nn.ReLU(),
                          nn.Linear(hidden_layer_neurons, out_features))

### END CODE HERE
model = model.to(device)
model

"""# Training

## Loss function
"""

criterion = nn.CrossEntropyLoss()

"""## Optimizer"""

# you have to change it for better performance

# adam
# optimizer = optim.Adam(model.parameters(), lr=1e-3)

# SGD
optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=3e-3)

"""## Others"""

# you can have other thongs like learning rate scheduler and ...

"""## Train"""

### START CODE HERE

losses = []
EPOCH = 100

# for training part you have to set model to train mode
model.train()

writer = SummaryWriter()

# loop on epochs
for e in tqdm(range(EPOCH)):

  # loop on batches
  true_positive = 0
  num_of_images = 0
  for inputs, labels in dataloaders['Training']:
    inputs = inputs.to(device)
    labels = labels.to(device)

    # set the grad to zero
    optimizer.zero_grad()
    
    # forward part
    # hint: using of pytorch max method (https://pytorch.org/docs/stable/generated/torch.max.html)
    outputs = model(inputs)
    _, preds = torch.max(outputs, 1)

    #  compute loss
    loss = criterion(outputs, labels)
    
    # backward part
    loss.backward()

    # update parameters
    optimizer.step()

    true_positive += np.count_nonzero(preds.cpu().numpy() == labels.cpu().numpy(), axis=0)
    num_of_images += len(labels.cpu().numpy())

  # you have to append loss for each epoch
  losses.append(loss.item())

  writer.add_scalar('Loss/train', loss.item(), e)
  writer.add_scalar('Accuracy/train', true_positive/num_of_images, e)
  print(f' - [X] For {e}th epoch: train accuracy: {true_positive}/{num_of_images} = {true_positive/num_of_images*100:.2f}')
### END CODE HERE

"""## Plot loss function"""

# you have to calculate losses arrayin Train part
plt.plot(list(range(len(losses))), losses)
plt.show()

"""## Evaluate model"""

### START CODE HERE

def calc_accuracy(data, model):
  corrects = 0

  # for testing part you have to set model to eval mode
  model.eval()
  for inputs, labels in tqdm(dataloaders[data]):
      inputs = inputs.to(device)
      labels = labels.to(device)
      
      with torch.no_grad():
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        corrects += torch.sum(preds == labels.data)
  return corrects.double() / dataset_sizes[data]

### END CODE HERE

# accuracy of training data
calc_accuracy('Training', model)

# accuracy of testing data
calc_accuracy('Testing', model)

"""# Saving Model"""

PATH = os.path.join(base_path, 'model')
torch.save(model.state_dict(), PATH)

"""# Loading and eval Model"""

### START CODE HERE

model_for_eval = models.resnet50(pretrained=True)
model_for_eval.fc = nn.Sequential(nn.Linear(model_for_eval.fc.in_features, hidden_layer_neurons),
                                        nn.ReLU(),
                                        nn.Linear(hidden_layer_neurons, hidden_layer_neurons),
                                        nn.ReLU(),
                                        nn.Linear(hidden_layer_neurons, out_features))
model_for_eval.to(device)
model_for_eval.load_state_dict(torch.load(PATH))

### END CODE HERE

model_for_eval

# accuracy of training data by loadded model
calc_accuracy('Training', model_for_eval)

# accuracy of testing data by loadded model
calc_accuracy('Testing', model_for_eval)